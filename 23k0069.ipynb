{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a3072d",
   "metadata": {},
   "source": [
    "23k0069\n",
    "## 1. Adding noise to an image:\n",
    "\n",
    "Given the dog image, write a Python code to add Gaussian noise sampled from a Gaussian distribution with a mean of 0 and a standard deviation of 15 to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736e1bd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the image (replace 'dog.jpg' with your image path)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image (replace 'dog.jpg' with your image path)\n",
    "image = cv2.imread('dog.jpg')\n",
    "\n",
    "# Convert image to float32 for precise computation\n",
    "image_float = image.astype(np.float32)\n",
    "\n",
    "# Generate Gaussian noise (mean=0, std=15)\n",
    "mean = 0\n",
    "std = 15\n",
    "gaussian_noise = np.random.normal(mean, std, image.shape)\n",
    "\n",
    "# Add noise to the image\n",
    "noisy_image = image_float + gaussian_noise\n",
    "\n",
    "# Clip values to valid range [0, 255]\n",
    "noisy_image = np.clip(noisy_image, 0, 255)\n",
    "\n",
    "# Convert back to uint8\n",
    "noisy_image = noisy_image.astype(np.uint8)\n",
    "\n",
    "# Save and display the result\n",
    "cv2.imwrite('dog_noisy.jpg', noisy_image)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Noisy Image', noisy_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6af870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\exam\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeed17f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the image (replace 'dog.jpg' with your image path)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image = cv2.imread('dog.jpg')\n",
    "\n",
    "image_float = image.astype(np.float32)\n",
    "\n",
    "\n",
    "mean = 0\n",
    "std = 15\n",
    "gaussian_noise = np.random.normal(mean, std, image.shape)\n",
    "\n",
    "\n",
    "noisy_image = image_float + gaussian_noise\n",
    "\n",
    "\n",
    "noisy_image = np.clip(noisy_image, 0, 255)\n",
    "\n",
    "\n",
    "noisy_image = noisy_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "cv2.imwrite('dog_noisy.jpg', noisy_image)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Noisy Image', noisy_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def convolve2d(image, kernel):\n",
    "    \n",
    "    img_h, img_w = image.shape\n",
    "    k_h, k_w = kernel.shape\n",
    "    \n",
    "    \n",
    "    pad_h = k_h // 2\n",
    "    pad_w = k_w // 2\n",
    "    \n",
    "    \n",
    "    padded_image = np.pad(image, \n",
    "                          ((pad_h, pad_h), (pad_w, pad_w)), \n",
    "                          mode='constant', \n",
    "                          constant_values=0)\n",
    "    \n",
    "    \n",
    "    flipped_kernel = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    \n",
    "    output = np.zeros((img_h, img_w))\n",
    "    \n",
    "    \n",
    "    for i in range(img_h):\n",
    "        for j in range(img_w):\n",
    "            region = padded_image[i:i+k_h, j:j+k_w]\n",
    "            output[i, j] = np.sum(region * flipped_kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "image = Image.open('dog.jpg').convert('L')\n",
    "image_array = np.array(image)\n",
    "\n",
    "\n",
    "Kernel = np.array([[1, 0, -1],\n",
    "                   [2, 0, -2],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "\n",
    "convolved_image = convolve2d(image_array, Kernel)\n",
    "\n",
    "\n",
    "convolved_image = np.clip(convolved_image, 0, 255)\n",
    "convolved_image = convolved_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "result_image = Image.fromarray(convolved_image)\n",
    "result_image.save('dog_convolved.jpg')\n",
    "result_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def convolve2d(image, kernel):\n",
    "    img_h, img_w = image.shape\n",
    "    k_h, k_w = kernel.shape\n",
    "    \n",
    "    pad_h = k_h // 2\n",
    "    pad_w = k_w // 2\n",
    "    \n",
    "    \n",
    "    padded = np.pad(image, \n",
    "                    ((pad_h, pad_h), (pad_w, pad_w)), \n",
    "                    mode='constant', constant_values=0)\n",
    "    \n",
    "    \n",
    "    kernel_flipped = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    output = np.zeros((img_h, img_w))\n",
    "    \n",
    "    for i in range(img_h):\n",
    "        for j in range(img_w):\n",
    "            region = padded[i:i+k_h, j:j+k_w]\n",
    "            output[i, j] = np.sum(region * kernel_flipped)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f651c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size=7, sigma=1.0):\n",
    "    ax = np.linspace(-(size//2), size//2, size)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    \n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * sigma**2))\n",
    "    \n",
    "    \n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('dog_noisy.jpg').convert('L')\n",
    "image_array = np.array(image).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11871d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = gaussian_kernel(size=7, sigma=1.0)\n",
    "\n",
    "denoised = convolve2d(image_array, gaussian)\n",
    "\n",
    "denoised = np.clip(denoised, 0, 255).astype(np.uint8)\n",
    "\n",
    "Image.fromarray(denoised).save('dog_denoised.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2026e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpening_kernel = np.array([\n",
    "    [1, 4, 6, 4, 1],\n",
    "    [4, 16, 24, 16, 4],\n",
    "    [6, 26, -476, 24, 6],\n",
    "    [4, 16, 24, 16, 4],\n",
    "    [1, 4, 6, 4, 1]\n",
    "]) * (-1.0 / 256.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064577a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpened = convolve2d(denoised.astype(np.float32), sharpening_kernel)\n",
    "\n",
    "sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "\n",
    "Image.fromarray(sharpened).save('dog_sharpened.jpg')\n",
    "Image.fromarray(sharpened).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7c97d",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "shelf = Image.open('shelf.jpg').convert('L')\n",
    "template = Image.open('template.jpg').convert('L')\n",
    "\n",
    "f = np.array(shelf).astype(np.float32)\n",
    "g = np.array(template).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_zero = f - np.mean(f)\n",
    "g_zero = g - np.mean(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e234404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation2d(image, template):\n",
    "    img_h, img_w = image.shape\n",
    "    t_h, t_w = template.shape\n",
    "    \n",
    "    output = np.zeros((img_h - t_h + 1, img_w - t_w + 1))\n",
    "    \n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            region = image[i:i+t_h, j:j+t_w]\n",
    "            output[i, j] = np.sum(region * template)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a61700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution2d(image, template):\n",
    "   \n",
    "    flipped_template = np.flipud(np.fliplr(template))\n",
    "    return correlation2d(image, flipped_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99965ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "corr_map = correlation2d(f_zero, g_zero)\n",
    "\n",
    "# Convolution\n",
    "conv_map = convolution2d(f_zero, g_zero)\n",
    "\n",
    "\n",
    "corr_y, corr_x = np.unravel_index(np.argmax(corr_map), corr_map.shape)\n",
    "conv_y, conv_x = np.unravel_index(np.argmax(conv_map), conv_map.shape)\n",
    "\n",
    "print(\"Correlation match location:\", (corr_y, corr_x))\n",
    "print(\"Convolution match location:\", (conv_y, conv_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, top_left, template_shape):\n",
    "    img_copy = image.copy()\n",
    "    y, x = top_left\n",
    "    h, w = template_shape\n",
    "    \n",
    "    plt.imshow(img_copy, cmap='gray')\n",
    "    plt.gca().add_patch(\n",
    "        plt.Rectangle((x, y), w, h,\n",
    "                      edgecolor='red',\n",
    "                      facecolor='none',\n",
    "                      linewidth=2)\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "print(\"Correlation Result:\")\n",
    "draw_rectangle(f, (corr_y, corr_x), g.shape)\n",
    "\n",
    "print(\"Convolution Result:\")\n",
    "draw_rectangle(f, (conv_y, conv_x), g.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60f0dd",
   "metadata": {},
   "source": [
    "### e. Which method more accurately locates the product?\n",
    "\n",
    " **Correlation typically performs better for template matching.**\n",
    "\n",
    "**Why?**\n",
    "\n",
    "- Correlation preserves the original orientation of the template.\n",
    "- Convolution flips the template before comparison.\n",
    "- If the object is not symmetric, flipping may reduce similarity.\n",
    "- Template matching is fundamentally about measuring similarity, not filtering.\n",
    "\n",
    "Therefore, correlation usually produces a more accurate location of the product on the shelf.\n",
    "\n",
    "---\n",
    "\n",
    "### f. Which method is more efficient?\n",
    "\n",
    " **Correlation is slightly more efficient in practice.**\n",
    "\n",
    "**Reasons:**\n",
    "\n",
    "- No flipping step is required.\n",
    "- Conceptually simpler to implement.\n",
    "- Most computer vision libraries (e.g., OpenCV `matchTemplate`) use correlation.\n",
    "- Both methods have similar computational complexity:\n",
    "\n",
    "\\[\n",
    "O(HW \\cdot hw)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( H, W \\) = dimensions of the shelf image  \n",
    "- \\( h, w \\) = dimensions of the template  \n",
    "\n",
    "Although complexity is the same, correlation avoids unnecessary preprocessing (flipping).\n",
    "\n",
    "---\n",
    "\n",
    "### g. Why is one method better suited?\n",
    "\n",
    " **Correlation is better suited for template matching.**\n",
    "\n",
    "**Because:**\n",
    "\n",
    "- Template matching measures similarity between image regions.\n",
    "- We want direct comparison between the template and the image patch.\n",
    "- Flipping (used in convolution) is intended for signal filtering, not similarity detection.\n",
    "\n",
    "In real-world computer vision:\n",
    "\n",
    "> ðŸ”¹ Template matching is almost always implemented using **correlation** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41964ff4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
